{"id":"gt-0kb","title":"Change default output filename from Groundtruth to Decisions","description":"","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-17T19:49:09.120633-08:00","updated_at":"2025-12-17T19:51:15.307481-08:00","closed_at":"2025-12-17T19:51:15.307481-08:00","close_reason":"Implemented in this commit"}
{"id":"gt-0ze","title":"Remove Meeting Dates section from Summary tab","description":"","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-17T19:48:54.451819-08:00","updated_at":"2025-12-17T19:51:15.306835-08:00","closed_at":"2025-12-17T19:51:15.306835-08:00","close_reason":"Implemented in this commit"}
{"id":"gt-4kp","title":"Parallel file processing for folder extraction","description":"Process multiple transcript files in parallel to achieve ~4x speedup for folder processing.\n\n## Context\n- Current: Sequential processing of 4 files takes 4-7 minutes\n- Each file: participant detection (6s) + extraction (60-100s)\n- Files are independent - no reason to process sequentially\n\n## Expected improvement\n```\nSequential: 4 files × 66s = 264s (4.4 min)\nParallel:   4 files / 4 workers = ~66s (1.1 min)\n```\n\n## Implementation\n```python\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\n\ndef extract_decisions_from_folder_parallel(folder_path, config, max_workers=4):\n    transcript_files = sorted(folder_path.glob(pattern))\n    \n    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n        futures = {\n            executor.submit(extract_file, f, config): f\n            for f in transcript_files\n        }\n        \n        results = []\n        for future in as_completed(futures):\n            file = futures[future]\n            try:\n                rows = future.result()\n                results.append((file, rows))\n            except Exception as e:\n                logger.error(f\"Failed: {file}: {e}\")\n        \n        return merge_results(results)\n```\n\n## Considerations\n- Rate limiting: May need to respect LLM provider limits\n- Error handling: One file failure shouldn't stop others\n- Progress reporting: Show which files are processing\n- Memory: All results held in memory until merge\n\n## Files to modify\n- src/groundtruth/llm.py: Add extract_decisions_from_folder_parallel()\n- src/groundtruth/cli.py: Add --parallel flag or make it default","acceptance_criteria":"- [ ] ThreadPoolExecutor used for parallel processing\n- [ ] Configurable max_workers (default 4)\n- [ ] Individual file failures don't stop batch\n- [ ] Progress logging shows which files are processing\n- [ ] Results correctly merged with different participant sets\n- [ ] Metrics track parallel vs sequential timing\n- [ ] Manual test shows ~4x speedup on 4-file folder","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-17T17:04:07.415291-08:00","updated_at":"2025-12-17T17:19:39.175757-08:00","closed_at":"2025-12-17T17:19:39.175757-08:00","close_reason":"Implemented parallel processing - 4 files in 143s (2.3x speedup), 66 decisions","labels":["performance"],"dependencies":[{"issue_id":"gt-4kp","depends_on_id":"gt-tvg","type":"blocks","created_at":"2025-12-17T17:04:07.418671-08:00","created_by":"daemon"}]}
{"id":"gt-704","title":"Add retry with exponential backoff for LLM calls","description":"Implement retry logic with exponential backoff for ClaudeCodeProvider.extract_decisions_json and detect_participants. Handle transient failures gracefully.","status":"closed","priority":1,"issue_type":"feature","created_at":"2025-12-17T17:52:04.168061-08:00","updated_at":"2025-12-17T17:52:17.112344-08:00","closed_at":"2025-12-17T17:52:17.112344-08:00","close_reason":"Duplicate of gt-jyb"}
{"id":"gt-hq3","title":"Externalize LLM prompts to markdown files","description":"Move hardcoded prompts from Python code to external markdown files for easier editing and maintenance. Currently prompts are embedded in config.py (build_json_extraction_prompt) and llm.py (PARTICIPANT_DETECTION_PROMPT).","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-17T17:52:00.265981-08:00","updated_at":"2025-12-17T18:18:58.74617-08:00","closed_at":"2025-12-17T18:18:58.74617-08:00","close_reason":"Closed"}
{"id":"gt-jyb","title":"Add retry with exponential backoff for LLM calls","description":"LLM calls (participant detection and decision extraction) intermittently return empty responses. Add retry mechanism with exponential backoff to improve reliability.\n\n## Context\n- Claude Code CLI sometimes returns empty/truncated responses\n- Current behavior: immediate failure on empty response\n- Observed: 54s extraction returning 1 char (empty)\n\n## Implementation\n- Add retry wrapper around LLM provider calls\n- Use exponential backoff: 1s, 2s, 4s delays\n- Max 3 retries before failing\n- Validate response has minimum expected content before accepting\n- Track retry count in metrics\n\n## Files to modify\n- src/groundtruth/llm.py: Add extract_with_retry() wrapper\n- Add retry_count to Metrics class","acceptance_criteria":"- [ ] Retry mechanism implemented with configurable max_retries\n- [ ] Exponential backoff between retries (1s, 2s, 4s)\n- [ ] Response validation before accepting (min length check)\n- [ ] Metrics track retry_count\n- [ ] Existing tests still pass\n- [ ] Manual test with folder processing shows improved reliability","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-17T17:03:35.843059-08:00","updated_at":"2025-12-17T17:03:35.843059-08:00","labels":["performance","reliability"]}
{"id":"gt-l14","title":"Add pytest test suite for groundtruth","description":"Create test suite using pytest. Include tests for: Decision model validation, JSON extraction parsing, parallel folder processing, config loading/merging. The project has pytest in dev dependencies but no tests yet.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-17T17:52:02.192113-08:00","updated_at":"2025-12-17T18:18:58.747582-08:00","closed_at":"2025-12-17T18:18:58.747582-08:00","close_reason":"Closed"}
{"id":"gt-o8u","title":"Rename Groundtruth tab to Decisions in Excel output","description":"","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-17T19:48:51.81076-08:00","updated_at":"2025-12-17T19:51:15.30475-08:00","closed_at":"2025-12-17T19:51:15.30475-08:00","close_reason":"Implemented in this commit"}
{"id":"gt-s66","title":"Summary tab: Show input files with per-file participants and deciders","description":"","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-17T19:48:53.278155-08:00","updated_at":"2025-12-17T19:51:15.306138-08:00","closed_at":"2025-12-17T19:51:15.306138-08:00","close_reason":"Implemented in this commit"}
{"id":"gt-tvg","title":"JSON intermediate format for decision extraction","description":"Replace direct CSV output from LLM with structured JSON intermediate format. Use Claude Code's --json-schema for validation.\n\n## Context\n- Current flow: Transcript → LLM → CSV string → Parse → Rows → XLSX\n- CSV parsing is fragile (header detection, column validation)\n- No caching possible with current architecture\n- Different participant sets per file need clean merging\n\n## Proposed flow\nTranscript → LLM → JSON → Validate → DecisionList → CSV/XLSX\n\n## JSON Schema\n```json\n{\n  \"decisions\": [{\n    \"category\": \"string\",\n    \"significance\": 1-5,\n    \"status\": \"Agreed|Needs Clarification|Unresolved\",\n    \"title\": \"string\",\n    \"description\": \"string\",\n    \"decision\": \"string\",\n    \"agreements\": {\"PersonName\": \"Yes|Partial|No\"},\n    \"notes\": \"string\",\n    \"meeting_date\": \"YYYY-MM-DD\",\n    \"meeting_reference\": \"filename\"\n  }],\n  \"metadata\": {\n    \"transcript_chars\": number,\n    \"extraction_time_ms\": number,\n    \"participants_detected\": [\"string\"]\n  }\n}\n```\n\n## Benefits\n- Use --json-schema for structured output validation\n- Enable result caching by transcript hash\n- Cleaner multi-file merging with different participants\n- Better error messages on parse failures\n\n## Files to modify\n- src/groundtruth/llm.py: Update extraction prompt, add JSON parsing\n- src/groundtruth/config.py: Add JSON schema definition\n- src/groundtruth/output.py: Convert JSON to CSV/XLSX","acceptance_criteria":"- [ ] JSON schema defined for decision output\n- [ ] LLM prompt updated to request JSON format\n- [ ] --json-schema flag used with Claude Code CLI\n- [ ] JSON response validation implemented\n- [ ] Conversion from JSON to CSV rows working\n- [ ] Conversion from JSON to XLSX working\n- [ ] Different participant sets merge correctly\n- [ ] Existing CLI interface unchanged (backward compatible)","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-17T17:03:51.653381-08:00","updated_at":"2025-12-17T17:19:37.381669-08:00","closed_at":"2025-12-17T17:19:37.381669-08:00","close_reason":"Implemented JSON intermediate format with Decision/ExtractionResult models","labels":["architecture","performance"]}
